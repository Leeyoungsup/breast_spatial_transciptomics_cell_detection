{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b39ece3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import warnings\n",
    "from argparse import ArgumentParser\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from torch.utils import data\n",
    "# ê°œë³„ json ë¼ë²¨ íŒŒì¼ì„ ì´ìš©í•´ í•™ìŠµ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "from glob import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import os\n",
    "from nets import ContextNn\n",
    "from utils import util\n",
    "from utils.dataset import Dataset\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import openslide\n",
    "import copy\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import math\n",
    "import numpy\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn.functional import cross_entropy\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\",device)\n",
    "params={'names':{\n",
    "             0: \"epithelial\",\n",
    "    1: \"Basal/Myoepithelial\",\n",
    "    2: \"Smooth muscle\",\n",
    "    3: \"Fibroblast\",\n",
    "    4: \"Endothelial\",\n",
    "    5: \"Lymphocyte\",                # T + B í†µí•©\n",
    "    6: \"Plasma cell\",\n",
    "    7: \"Macrophage/Histiocyte\",     # í†µí•©\n",
    "    8: \"Neutrophil\",\n",
    "    9: \"Adipocyte\",\n",
    "    10: \"Other/Unknown\"\n",
    "        }}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir='../../model/Breast_ST_context/'\n",
    "model = ContextNn.yolo_v11_m(len(params['names']), use_context=True, context_backbone='efficientnet_b1').to(device)\n",
    "checkpoint_path = os.path.join(save_dir, 'best_model.pt')\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device,weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "def wh2xy(x):\n",
    "    y = x.clone() if isinstance(x, torch.Tensor) else numpy.copy(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "    return y\n",
    "   \n",
    "def non_max_suppression(outputs, confidence_threshold=0.001, iou_threshold=0.65, class_thresholds=None):\n",
    "    \"\"\"\n",
    "    ë¹ ë¥¸ í´ë˜ìŠ¤ë³„ NMS - ì„±ëŠ¥ ìµœì í™” ë²„ì „\n",
    "    \"\"\"\n",
    "    max_wh = 7680\n",
    "    max_det = 300\n",
    "    max_nms = 30000\n",
    "\n",
    "    bs = outputs.shape[0]\n",
    "    nc = outputs.shape[1] - 4\n",
    "    \n",
    "    # ë¹ ë¥¸ í•„í„°ë§ì„ ìœ„í•´ ê°€ì¥ ë‚®ì€ threshold ì‚¬ìš©\n",
    "    min_conf = confidence_threshold\n",
    "    if class_thresholds:\n",
    "        min_conf = min(min(class_thresholds.values()), confidence_threshold)\n",
    "    \n",
    "    # ì „ì²´ confidenceê°€ ë‚®ì€ ê²ƒë“¤ ë¨¼ì € ì œê±°\n",
    "    xc = outputs[:, 4:4 + nc].amax(1) > min_conf\n",
    "    \n",
    "    output = [torch.zeros((0, 6), device=outputs.device)] * bs\n",
    "    \n",
    "    for xi, x in enumerate(outputs):  # image index, image inference\n",
    "        x = x.transpose(0, -1)[xc[xi]]\n",
    "        \n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # ë°•ìŠ¤ì™€ í´ë˜ìŠ¤ ë¶„ë¦¬\n",
    "        box, cls = x.split((4, nc), 1)\n",
    "        box = wh2xy(box)\n",
    "        \n",
    "        # ê° ê²€ì¶œì˜ ìµœê³  í´ë˜ìŠ¤ì™€ confidence ì°¾ê¸°\n",
    "        conf, j = cls.max(1, keepdim=True)\n",
    "        x = torch.cat((box, conf, j.float()), 1)\n",
    "        \n",
    "        # í´ë˜ìŠ¤ë³„ threshold ì ìš© (ê°„ë‹¨í•œ ë°©ì‹)\n",
    "        if class_thresholds:\n",
    "            keep = torch.zeros(x.shape[0], dtype=torch.bool, device=x.device)\n",
    "            for i, detection in enumerate(x):\n",
    "                class_id = int(detection[5].item())\n",
    "                threshold = class_thresholds.get(class_id, confidence_threshold)\n",
    "                if detection[4].item() >= threshold:\n",
    "                    keep[i] = True\n",
    "            x = x[keep]\n",
    "        else:\n",
    "            x = x[x[:, 4] > confidence_threshold]\n",
    "        \n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "            \n",
    "        # confidenceë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ max_nmsê°œë§Œ ìœ ì§€\n",
    "        x = x[x[:, 4].argsort(descending=True)[:max_nms]]\n",
    "        \n",
    "        # ë¹ ë¥¸ NMS - PyTorch ë‚´ì¥ í•¨ìˆ˜ ì‚¬ìš©\n",
    "        c = x[:, 5:6] * max_wh  # í´ë˜ìŠ¤ë³„ offset\n",
    "        boxes = x[:, :4] + c\n",
    "        scores = x[:, 4]\n",
    "        \n",
    "        # NMS ì ìš©\n",
    "        keep = torchvision.ops.nms(boxes, scores, iou_threshold)\n",
    "        if keep.shape[0] > max_det:\n",
    "            keep = keep[:max_det]\n",
    "        \n",
    "        output[xi] = x[keep]\n",
    "    \n",
    "    return output\n",
    "    \n",
    "def pred_patch(torch_patch, torch_tissue, model, start_x, start_y, magnification):\n",
    "    model.eval()\n",
    "    \n",
    "    # HnE ì„¸í¬ ë¶„ë¥˜ë¥¼ ìœ„í•œ í´ë˜ìŠ¤ë³„ ê°œë³„ confidence threshold ì„¤ì •\n",
    "    class_thresholds = {\n",
    "        0: 0.2,   \n",
    "        1: 0.2,   \n",
    "        2: 0.2,   \n",
    "        3: 0.2,   \n",
    "        4: 0.3,   \n",
    "        5: 0.2,  \n",
    "        6: 0.2,   \n",
    "        7: 0.2,   \n",
    "        8: 0.2,   \n",
    "        9: 0.2,  \n",
    "        10: 0.2,  \n",
    "    }\n",
    "    \n",
    "    # ê° í´ë˜ìŠ¤ë³„ ì„¸í¬ ë¦¬ìŠ¤íŠ¸ (ì„ì‹œë¡œ ê¸°ì¡´ ë³€ìˆ˜ëª… ìœ ì§€)\n",
    "    cells_list = []  # ëª¨ë“  ê²€ì¶œëœ ì„¸í¬ë¥¼ ì—¬ê¸°ì— ì €ì¥\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            pred = model(torch_patch, tissue_context=torch_tissue)\n",
    "        \n",
    "        # ë¹ ë¥¸ NMS ì ìš© (ì „ì²´ thresholdë¥¼ ë‚®ê²Œ ì„¤ì •í•˜ì—¬ í´ë˜ìŠ¤ë³„ thresholdê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ë„ë¡)\n",
    "        results = non_max_suppression(pred, confidence_threshold=0.2, \n",
    "                                    iou_threshold=0.45, class_thresholds=class_thresholds)\n",
    "        \n",
    "        if len(results[0]) > 0:\n",
    "            # ë²¡í„°í™”ëœ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ\n",
    "            detections = results[0]\n",
    "            xyxy = detections[:, :4]\n",
    "            confs = detections[:, 4]\n",
    "            cls_ids = detections[:, 5]\n",
    "            \n",
    "            # ì¤‘ì‹¬ì  ê³„ì‚° (ë²¡í„°í™”)\n",
    "            centers_x = (xyxy[:, 0] + xyxy[:, 2]) / 2\n",
    "            centers_y = (xyxy[:, 1] + xyxy[:, 3]) / 2\n",
    "            \n",
    "            # ì‹¤ì œ ì¢Œí‘œ ê³„ì‚°\n",
    "            actual_x = start_x + centers_x * magnification\n",
    "            actual_y = start_y + centers_y * magnification\n",
    "            \n",
    "            # ëª¨ë“  í´ë˜ìŠ¤ì˜ ì„¸í¬ë¥¼ cells_list ë¦¬ìŠ¤íŠ¸ì— ì €ì¥ (ë²¡í„°í™”)\n",
    "            for i in range(len(detections)):\n",
    "                cls_id = int(cls_ids[i].item())\n",
    "                cell_data = {\n",
    "                    'x': actual_x[i].item(), \n",
    "                    'y': actual_y[i].item(), \n",
    "                    'cls_id': cls_id,\n",
    "                    'confidence': confs[i].item()\n",
    "                }\n",
    "                \n",
    "                # ëª¨ë“  ì„¸í¬ë¥¼ cells_listì— ì €ì¥ (XML ìƒì„± í•¨ìˆ˜ì—ì„œ cls_idë¡œ êµ¬ë¶„)\n",
    "                cells_list.append(cell_data)\n",
    "    \n",
    "    return cells_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb2b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_patch_cells_to_json(cells_list, temp_dir, patch_id):\n",
    "    \"\"\"ê° íŒ¨ì¹˜ë³„ë¡œ ê°œë³„ JSON íŒŒì¼ì— ì €ì¥ (íŒŒì‹± ì—†ìŒ!)\"\"\"\n",
    "    if not cells_list:\n",
    "        return\n",
    "    \n",
    "    patch_json_path = os.path.join(temp_dir, f\"patch_{patch_id}.json\")\n",
    "    \n",
    "    # ì§ì ‘ ì €ì¥ (íŒŒì¼ ì½ê¸°/íŒŒì‹± ì „í˜€ ì—†ìŒ!)\n",
    "    with open(patch_json_path, 'w') as f:\n",
    "        json.dump(cells_list, f)\n",
    "\n",
    "def merge_patch_jsons_to_xml(temp_dir, xml_path):\n",
    "    \"\"\"temp í´ë”ì˜ ëª¨ë“  ê°œë³„ JSON íŒŒì¼ì„ ë³‘í•©í•˜ì—¬ XMLë¡œ ë³€í™˜\"\"\"\n",
    "    \n",
    "    # temp í´ë”ì˜ ëª¨ë“  JSON íŒŒì¼ ìˆ˜ì§‘\n",
    "    json_files = glob(os.path.join(temp_dir, \"patch_*.json\"))\n",
    "    all_cells = []\n",
    "    \n",
    "    print(f\"ğŸ“„ {len(json_files)}ê°œì˜ íŒ¨ì¹˜ JSON íŒŒì¼ ë³‘í•© ì¤‘...\")\n",
    "    \n",
    "    # ëª¨ë“  JSON íŒŒì¼ì—ì„œ ì„¸í¬ ë°ì´í„° ìˆ˜ì§‘\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, 'r') as f:\n",
    "            patch_cells = json.load(f)\n",
    "            all_cells.extend(patch_cells)\n",
    "    \n",
    "    # HnE ì„¸í¬ ë¶„ë¥˜ë¥¼ ìœ„í•œ í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ë§¤í•‘\n",
    "    class_colors = [\n",
    "    \"#FF0000\",\"#FFA500\",\n",
    "    \"#8B4513\",\n",
    "    \"#00FF00\",\n",
    "    \"#0000FF\",\n",
    "    \"#FFFF00\",\n",
    "    \"#FF00FF\",\n",
    "    \"#9400D3\",\n",
    "    \"#00FFFF\",\n",
    "    \"#FF6060\",\n",
    "    \"#808080\"\n",
    "    ]\n",
    "    class_names = {\n",
    "    0: \"epithelial\",\n",
    "    1: \"Basal/Myoepithelial\",\n",
    "    2: \"Smooth muscle\",\n",
    "    3: \"Fibroblast\",\n",
    "    4: \"Endothelial\",\n",
    "    5: \"Lymphocyte\",                # T + B í†µí•©\n",
    "    6: \"Plasma cell\",\n",
    "    7: \"Macrophage/Histiocyte\",     # í†µí•©\n",
    "    8: \"Neutrophil\",\n",
    "    9: \"Adipocyte\",\n",
    "    10: \"Other/Unknown\"\n",
    "    }\n",
    "    \n",
    "    # ë£¨íŠ¸ ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±\n",
    "    root = ET.Element(\"ASAP_Annotations\")\n",
    "    \n",
    "    # Annotations ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±\n",
    "    annotations = ET.SubElement(root, \"Annotations\")\n",
    "    \n",
    "    # í•œ ë²ˆì— ëª¨ë“  ì„¸í¬ ì¶”ê°€\n",
    "    annotation_id = 0\n",
    "    for cell in all_cells:\n",
    "        \n",
    "        cls_id = cell['cls_id'] # ê¸°ë³¸ê°’ì„ Unknownìœ¼ë¡œ ì„¤ì •\n",
    "        cls_id = int(cls_id)  # Ensure cls_id is an integer\n",
    "        \n",
    "        annotation = ET.SubElement(annotations, \"Annotation\")\n",
    "        annotation.set(\"Name\", f\"Annotation {annotation_id}\")\n",
    "        annotation.set(\"Type\", \"Dot\")\n",
    "        annotation.set(\"PartOfGroup\", class_names[cls_id])\n",
    "        annotation.set(\"Color\", class_colors[cls_id])\n",
    "        \n",
    "        coordinates = ET.SubElement(annotation, \"Coordinates\")\n",
    "        coordinate = ET.SubElement(coordinates, \"Coordinate\")\n",
    "        coordinate.set(\"Order\", \"0\")\n",
    "        coordinate.set(\"X\", str(float(cell['x'])))\n",
    "        coordinate.set(\"Y\", str(float(cell['y'])))\n",
    "        \n",
    "        annotation_id += 1\n",
    "    \n",
    "    # AnnotationGroups ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±\n",
    "    annotation_groups = ET.SubElement(root, \"AnnotationGroups\")\n",
    "    \n",
    "    # ê° í´ë˜ìŠ¤ë³„ ê·¸ë£¹ ìƒì„±\n",
    "    for cls_id, class_name in class_names.items():\n",
    "        group = ET.SubElement(annotation_groups, \"Group\")\n",
    "        group.set(\"Name\", class_name)\n",
    "        group.set(\"PartOfGroup\", class_name)\n",
    "        group.set(\"Color\", class_colors[cls_id])\n",
    "        \n",
    "        attributes = ET.SubElement(group, \"Attributes\")\n",
    "    \n",
    "    # XML ì €ì¥\n",
    "    rough_string = ET.tostring(root, 'unicode')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    pretty_xml = reparsed.toprettyxml(indent=\"\t\")\n",
    "    \n",
    "    # <?xml version... ë¼ì¸ì„ ì›í•˜ëŠ” í˜•íƒœë¡œ ìˆ˜ì •\n",
    "    lines = pretty_xml.split('\\n')\n",
    "    lines[0] = '<?xml version=\"1.0\"?>'\n",
    "    pretty_xml = '\\n'.join(lines[1:])  # ë¹ˆ ë¼ì¸ ì œê±°\n",
    "    \n",
    "    with open(xml_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(pretty_xml)\n",
    "    \n",
    "    print(f\"âœ… XML ë³€í™˜ ì™„ë£Œ: {len(all_cells)}ê°œ ì„¸í¬\")\n",
    "    return len(all_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2021d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3611.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "ì²˜ë¦¬ëœ íŒ¨ì¹˜: 1, ì´ ê²€ì¶œëœ ì„¸í¬: 0:   0%|          | 0/141 [00:01<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3611.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "ì²˜ë¦¬ëœ íŒ¨ì¹˜: 10483, ì´ ê²€ì¶œëœ ì„¸í¬: 238439: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 141/141 [18:28<00:00,  7.86s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“„ ê°œë³„ JSON íŒŒì¼ë“¤ ë³‘í•©í•˜ì—¬ XML ë³€í™˜ ì¤‘...\n",
      "ğŸ“„ 7143ê°œì˜ íŒ¨ì¹˜ JSON íŒŒì¼ ë³‘í•© ì¤‘...\n",
      "âœ… XML ë³€í™˜ ì™„ë£Œ: 238439ê°œ ì„¸í¬\n",
      "âœ… XML ë³€í™˜ ì™„ë£Œ: 238439ê°œ ì„¸í¬\n",
      "ğŸ¯ WSI ì²˜ë¦¬ ì™„ë£Œ! ì´ 238439ê°œ ì„¸í¬ ê²€ì¶œë¨\n",
      "ğŸ“„ XML íŒŒì¼ ì €ì¥ ìœ„ì¹˜: ../../results/Breast_RNA_transcripts/NIPA-BRCA-KN-00013-S-TP-01.xml\n",
      "ğŸ—‘ï¸  ì„ì‹œ í´ë” ì •ë¦¬ ì™„ë£Œ\n",
      "ğŸ¯ WSI ì²˜ë¦¬ ì™„ë£Œ! ì´ 238439ê°œ ì„¸í¬ ê²€ì¶œë¨\n",
      "ğŸ“„ XML íŒŒì¼ ì €ì¥ ìœ„ì¹˜: ../../results/Breast_RNA_transcripts/NIPA-BRCA-KN-00013-S-TP-01.xml\n",
      "ğŸ—‘ï¸  ì„ì‹œ í´ë” ì •ë¦¬ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì²˜ë¦¬ëœ íŒ¨ì¹˜: 17466, ì´ ê²€ì¶œëœ ì„¸í¬: 729108:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 85/141 [17:59<11:50, 12.69s/it]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m torch_tissue \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(tissue_patch)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Tissue contextë¥¼ í¬í•¨í•œ ì˜ˆì¸¡\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m cell_list \u001b[38;5;241m=\u001b[39m \u001b[43mpred_patch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_patch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_tissue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_row\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_col\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# ğŸš€ ê°œë³„ JSON íŒŒì¼ë¡œ ì €ì¥ (íŒŒì¼ íŒŒì‹± ì „í˜€ ì—†ìŒ!)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cell_list) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[2], line 110\u001b[0m, in \u001b[0;36mpred_patch\u001b[0;34m(torch_patch, torch_tissue, model, start_x, start_y, magnification)\u001b[0m\n\u001b[1;32m    107\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(torch_patch, tissue_context\u001b[38;5;241m=\u001b[39mtorch_tissue)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# ë¹ ë¥¸ NMS ì ìš© (ì „ì²´ thresholdë¥¼ ë‚®ê²Œ ì„¤ì •í•˜ì—¬ í´ë˜ìŠ¤ë³„ thresholdê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ë„ë¡)\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mnon_max_suppression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfidence_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                            \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.45\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_thresholds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_thresholds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# ë²¡í„°í™”ëœ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     detections \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[2], line 58\u001b[0m, in \u001b[0;36mnon_max_suppression\u001b[0;34m(outputs, confidence_threshold, iou_threshold, class_thresholds)\u001b[0m\n\u001b[1;32m     56\u001b[0m         threshold \u001b[38;5;241m=\u001b[39m class_thresholds\u001b[38;5;241m.\u001b[39mget(class_id, confidence_threshold)\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m detection[\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold:\n\u001b[0;32m---> 58\u001b[0m             keep[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[keep]\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pyvips\n",
    "import shutil\n",
    "\n",
    "slide_path=glob('../../data/BR_HnE/*.ndpi')\n",
    "image_size=1024 # ëª¨ë¸ ì…ë ¥ í¬ê¸°\n",
    "origin_mpp=0.25\n",
    "output_mpp=0.5\n",
    "original_size=int(image_size*output_mpp/origin_mpp) #1122\n",
    "magnification=original_size/image_size\n",
    "count=0\n",
    "\n",
    "for i in range(len(slide_path)):\n",
    "    file_name=os.path.basename(slide_path[i]).split('.')[0]\n",
    "    slide=openslide.OpenSlide(slide_path[i])\n",
    "    thumbnail=slide.get_thumbnail((slide.dimensions[0]//64, slide.dimensions[1]//64))\n",
    "    \n",
    "    tissue_slide=slide.get_thumbnail((slide.dimensions[0]//8, slide.dimensions[1]//8))\n",
    "    slide = pyvips.Image.new_from_file(slide_path[i])\n",
    "    tissue_slide=np.array(tissue_slide)\n",
    "    thumb_mask=cv2.threshold(255-np.array(thumbnail.convert('L')),30,255,cv2.THRESH_BINARY)[1]\n",
    "    thumb_mask=cv2.morphologyEx(thumb_mask,cv2.MORPH_CLOSE,np.ones((15,15),np.uint8))\n",
    "    thumb_mask=cv2.morphologyEx(thumb_mask,cv2.MORPH_OPEN,np.ones((5,5),np.uint8))\n",
    "    \n",
    "    # íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "    output_xml_path = f\"../../results/Breast_RNA_transcripts/{file_name}.xml\"\n",
    "    temp_dir = f\"../../results/Breast_RNA_transcripts/cell_detection/{file_name}_temp\"\n",
    "    os.makedirs(\"../../results/Breast_RNA_transcripts/cell_detection\", exist_ok=True)\n",
    "    \n",
    "    # temp í´ë” ì´ˆê¸°í™” (ê¸°ì¡´ í´ë” ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±)\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "    os.makedirs(temp_dir)\n",
    "    \n",
    "    total_cells_detected = 0\n",
    "    patch_counter = 0  # íŒ¨ì¹˜ ID ì¹´ìš´í„°\n",
    "    row_pbar = tqdm(range(slide.width//image_size-1), total=slide.width//image_size-1)\n",
    "    \n",
    "    for patch_row in row_pbar:\n",
    "        for patch_col in range(slide.height//image_size-1):\n",
    "            if np.sum(thumb_mask[(patch_col*image_size)//64:((patch_col+1)*image_size)//64,(patch_row*image_size)//64:((patch_row+1)*image_size)//64])>0:\n",
    "                count+=1\n",
    "                \n",
    "                # ë©”ì¸ íŒ¨ì¹˜ ì¶”ì¶œ\n",
    "                patch=slide.crop(patch_row*image_size, patch_col*image_size, image_size, image_size)\n",
    "                patch=np.ndarray(buffer=patch.write_to_memory(),\n",
    "                            dtype=np.uint8,\n",
    "                            shape=[patch.height, patch.width, patch.bands])\n",
    "                patch = cv2.resize(np.array(patch)[:,:,:3], (512, 512))\n",
    "                \n",
    "                # Tissue context íŒ¨ì¹˜ ì¶”ì¶œ (ë©”ì¸ íŒ¨ì¹˜ ì¤‘ì‹¬ìœ¼ë¡œ 4ë°° í¬ê¸° ì˜ì—­)\n",
    "                tissue_patch_x = patch_row*image_size - image_size//2 - image_size\n",
    "                tissue_patch_y = patch_col*image_size - image_size//2 - image_size\n",
    "                \n",
    "                # ê²½ê³„ ì²˜ë¦¬\n",
    "                if tissue_patch_x < 0:\n",
    "                    tissue_patch_x = 0\n",
    "                if tissue_patch_y < 0:\n",
    "                    tissue_patch_y = 0\n",
    "                if tissue_patch_x + image_size*4 > slide.width:\n",
    "                    tissue_patch_x = slide.width - image_size*4\n",
    "                if tissue_patch_y + image_size*4 > slide.height:\n",
    "                    tissue_patch_y = slide.height - image_size*4\n",
    "                \n",
    "                # Tissue context íŒ¨ì¹˜ ì¶”ì¶œ (4ë°° ì˜ì—­)\n",
    "                tissue_patch = tissue_slide[tissue_patch_y//8:tissue_patch_y//8 + 512, tissue_patch_x//8:tissue_patch_x//8 + 512, :]\n",
    "                \n",
    "                # ë©”ì¸ íŒ¨ì¹˜ì™€ tissue contextë¥¼ ëª¨ë‘ tensorë¡œ ë³€í™˜\n",
    "                torch_patch = torch.from_numpy(patch).permute(2,0,1).unsqueeze(0).to(device, dtype=torch.float32) / 255.0\n",
    "                torch_tissue = torch.from_numpy(tissue_patch).permute(2,0,1).unsqueeze(0).to(device, dtype=torch.float32) / 255.0\n",
    "                \n",
    "                # Tissue contextë¥¼ í¬í•¨í•œ ì˜ˆì¸¡\n",
    "                cell_list = pred_patch(torch_patch, torch_tissue, model, patch_row*image_size, patch_col*image_size, 2)\n",
    "                \n",
    "                # ğŸš€ ê°œë³„ JSON íŒŒì¼ë¡œ ì €ì¥ (íŒŒì¼ íŒŒì‹± ì „í˜€ ì—†ìŒ!)\n",
    "                if len(cell_list) > 0:\n",
    "                    save_patch_cells_to_json(cell_list, temp_dir, patch_counter)\n",
    "                    total_cells_detected += len(cell_list)\n",
    "                \n",
    "                patch_counter += 1  # íŒ¨ì¹˜ ID ì¦ê°€\n",
    "                s = f\"ì²˜ë¦¬ëœ íŒ¨ì¹˜: {count}, ì´ ê²€ì¶œëœ ì„¸í¬: {total_cells_detected}\"\n",
    "                row_pbar.set_description(f'{s}')\n",
    "\n",
    "    # ğŸ¯ ì²˜ë¦¬ ì™„ë£Œ í›„ ëª¨ë“  ê°œë³„ JSON â†’ XML ì¼ê´„ ë³€í™˜\n",
    "    print(f\"\\nğŸ“„ ê°œë³„ JSON íŒŒì¼ë“¤ ë³‘í•©í•˜ì—¬ XML ë³€í™˜ ì¤‘...\")\n",
    "    final_cell_count = merge_patch_jsons_to_xml(temp_dir, output_xml_path)\n",
    "    \n",
    "    # temp í´ë” ì „ì²´ ì‚­ì œ\n",
    "    shutil.rmtree(temp_dir)\n",
    "    \n",
    "    print(f\"ğŸ¯ WSI ì²˜ë¦¬ ì™„ë£Œ! ì´ {final_cell_count}ê°œ ì„¸í¬ ê²€ì¶œë¨\")\n",
    "    print(f\"ğŸ“„ XML íŒŒì¼ ì €ì¥ ìœ„ì¹˜: {output_xml_path}\")\n",
    "    print(f\"ğŸ—‘ï¸  ì„ì‹œ í´ë” ì •ë¦¬ ì™„ë£Œ\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d19349c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_patch.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee49b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_xml_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
