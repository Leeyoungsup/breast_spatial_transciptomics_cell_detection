{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import warnings\n",
    "from argparse import ArgumentParser\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from torch.utils import data\n",
    "# ê°œë³„ json ë¼ë²¨ íŒŒì¼ì„ ì´ìš©í•´ í•™ìŠµ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "from glob import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import os\n",
    "from nets import nn\n",
    "from utils import util\n",
    "from utils.dataset import Dataset\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import openslide\n",
    "import copy\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import math\n",
    "import numpy\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn.functional import cross_entropy\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\",device)\n",
    "params={'names':{\n",
    "            0: \"Neutrophil\",\n",
    "            1: \"Epithelial\",\n",
    "            2: \"Lymphocyte\",\n",
    "            3: \"Plasma\",\n",
    "            4: \"Eosinophil\",\n",
    "            5: \"Connective tissue\"\n",
    "        }}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir='../../model/HnE_cell_detection/yolov11/'\n",
    "model = nn.yolo_v11_m(len(params['names'])).to(device)\n",
    "checkpoint_path = os.path.join(save_dir, 'best_model_m.pt')\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device,weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "def wh2xy(x):\n",
    "    y = x.clone() if isinstance(x, torch.Tensor) else numpy.copy(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "    return y\n",
    "   \n",
    "def non_max_suppression(outputs, confidence_threshold=0.001, iou_threshold=0.65, class_thresholds=None):\n",
    "    \"\"\"\n",
    "    ë¹ ë¥¸ í´ë˜ìŠ¤ë³„ NMS - ì„±ëŠ¥ ìµœì í™” ë²„ì „\n",
    "    \"\"\"\n",
    "    max_wh = 7680\n",
    "    max_det = 300\n",
    "    max_nms = 30000\n",
    "\n",
    "    bs = outputs.shape[0]\n",
    "    nc = outputs.shape[1] - 4\n",
    "    \n",
    "    # ë¹ ë¥¸ í•„í„°ë§ì„ ìœ„í•´ ê°€ì¥ ë‚®ì€ threshold ì‚¬ìš©\n",
    "    min_conf = confidence_threshold\n",
    "    if class_thresholds:\n",
    "        min_conf = min(min(class_thresholds.values()), confidence_threshold)\n",
    "    \n",
    "    # ì „ì²´ confidenceê°€ ë‚®ì€ ê²ƒë“¤ ë¨¼ì € ì œê±°\n",
    "    xc = outputs[:, 4:4 + nc].amax(1) > min_conf\n",
    "    \n",
    "    output = [torch.zeros((0, 6), device=outputs.device)] * bs\n",
    "    \n",
    "    for xi, x in enumerate(outputs):  # image index, image inference\n",
    "        x = x.transpose(0, -1)[xc[xi]]\n",
    "        \n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # ë°•ìŠ¤ì™€ í´ë˜ìŠ¤ ë¶„ë¦¬\n",
    "        box, cls = x.split((4, nc), 1)\n",
    "        box = wh2xy(box)\n",
    "        \n",
    "        # ê° ê²€ì¶œì˜ ìµœê³  í´ë˜ìŠ¤ì™€ confidence ì°¾ê¸°\n",
    "        conf, j = cls.max(1, keepdim=True)\n",
    "        x = torch.cat((box, conf, j.float()), 1)\n",
    "        \n",
    "        # í´ë˜ìŠ¤ë³„ threshold ì ìš© (ê°„ë‹¨í•œ ë°©ì‹)\n",
    "        if class_thresholds:\n",
    "            keep = torch.zeros(x.shape[0], dtype=torch.bool, device=x.device)\n",
    "            for i, detection in enumerate(x):\n",
    "                class_id = int(detection[5].item())\n",
    "                threshold = class_thresholds.get(class_id, confidence_threshold)\n",
    "                if detection[4].item() >= threshold:\n",
    "                    keep[i] = True\n",
    "            x = x[keep]\n",
    "        else:\n",
    "            x = x[x[:, 4] > confidence_threshold]\n",
    "        \n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "            \n",
    "        # confidenceë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ max_nmsê°œë§Œ ìœ ì§€\n",
    "        x = x[x[:, 4].argsort(descending=True)[:max_nms]]\n",
    "        \n",
    "        # ë¹ ë¥¸ NMS - PyTorch ë‚´ì¥ í•¨ìˆ˜ ì‚¬ìš©\n",
    "        c = x[:, 5:6] * max_wh  # í´ë˜ìŠ¤ë³„ offset\n",
    "        boxes = x[:, :4] + c\n",
    "        scores = x[:, 4]\n",
    "        \n",
    "        # NMS ì ìš©\n",
    "        keep = torchvision.ops.nms(boxes, scores, iou_threshold)\n",
    "        if keep.shape[0] > max_det:\n",
    "            keep = keep[:max_det]\n",
    "        \n",
    "        output[xi] = x[keep]\n",
    "    \n",
    "    return output\n",
    "    \n",
    "def pred_patch(torch_patch, model, start_x, start_y, magnification):\n",
    "    model.eval()\n",
    "    \n",
    "    # HnE ì„¸í¬ ë¶„ë¥˜ë¥¼ ìœ„í•œ í´ë˜ìŠ¤ë³„ ê°œë³„ confidence threshold ì„¤ì •\n",
    "    class_thresholds = {\n",
    "        0: 0.05,  # Neutrophil\n",
    "        1: 0.05,  # Epithelial\n",
    "        2: 0.05,  # Lymphocyte\n",
    "        3: 0.05,  # Plasma\n",
    "        4: 0.05,  # Eosinophil\n",
    "        5: 0.05   # Connective tissue\n",
    "    }\n",
    "    \n",
    "    # ê° í´ë˜ìŠ¤ë³„ ì„¸í¬ ë¦¬ìŠ¤íŠ¸ (ì„ì‹œë¡œ ê¸°ì¡´ ë³€ìˆ˜ëª… ìœ ì§€)\n",
    "    cells_list = []  # ëª¨ë“  ê²€ì¶œëœ ì„¸í¬ë¥¼ ì—¬ê¸°ì— ì €ì¥\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            pred = model(torch_patch)\n",
    "        \n",
    "        # ë¹ ë¥¸ NMS ì ìš©\n",
    "        results = non_max_suppression(pred, confidence_threshold=0.05, \n",
    "                                    iou_threshold=0.3, class_thresholds=class_thresholds)\n",
    "        \n",
    "        if len(results[0]) > 0:\n",
    "            # ë²¡í„°í™”ëœ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ\n",
    "            detections = results[0]\n",
    "            xyxy = detections[:, :4]\n",
    "            confs = detections[:, 4]\n",
    "            cls_ids = detections[:, 5]\n",
    "            \n",
    "            # ì¤‘ì‹¬ì  ê³„ì‚° (ë²¡í„°í™”)\n",
    "            centers_x = (xyxy[:, 0] + xyxy[:, 2]) / 2\n",
    "            centers_y = (xyxy[:, 1] + xyxy[:, 3]) / 2\n",
    "            \n",
    "            # ì‹¤ì œ ì¢Œí‘œ ê³„ì‚°\n",
    "            actual_x = start_x + centers_x * magnification\n",
    "            actual_y = start_y + centers_y * magnification\n",
    "            \n",
    "            # ëª¨ë“  í´ë˜ìŠ¤ì˜ ì„¸í¬ë¥¼ cells_list ë¦¬ìŠ¤íŠ¸ì— ì €ì¥ (ë²¡í„°í™”)\n",
    "            for i in range(len(detections)):\n",
    "                cls_id = int(cls_ids[i].item())\n",
    "                cell_data = {\n",
    "                    'x': actual_x[i].item(), \n",
    "                    'y': actual_y[i].item(), \n",
    "                    'cls_id': cls_id,\n",
    "                    'confidence': confs[i].item()\n",
    "                }\n",
    "                \n",
    "                # ëª¨ë“  ì„¸í¬ë¥¼ cells_listì— ì €ì¥ (XML ìƒì„± í•¨ìˆ˜ì—ì„œ cls_idë¡œ êµ¬ë¶„)\n",
    "                cells_list.append(cell_data)\n",
    "    \n",
    "    return cells_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_patch_cells_to_json(cells_list, temp_dir, patch_id):\n",
    "    \"\"\"ê° íŒ¨ì¹˜ë³„ë¡œ ê°œë³„ JSON íŒŒì¼ì— ì €ì¥ (íŒŒì‹± ì—†ìŒ!)\"\"\"\n",
    "    if not cells_list:\n",
    "        return\n",
    "    \n",
    "    patch_json_path = os.path.join(temp_dir, f\"patch_{patch_id}.json\")\n",
    "    \n",
    "    # ì§ì ‘ ì €ì¥ (íŒŒì¼ ì½ê¸°/íŒŒì‹± ì „í˜€ ì—†ìŒ!)\n",
    "    with open(patch_json_path, 'w') as f:\n",
    "        json.dump(cells_list, f)\n",
    "\n",
    "def merge_patch_jsons_to_xml(temp_dir, xml_path):\n",
    "    \"\"\"temp í´ë”ì˜ ëª¨ë“  ê°œë³„ JSON íŒŒì¼ì„ ë³‘í•©í•˜ì—¬ XMLë¡œ ë³€í™˜\"\"\"\n",
    "    \n",
    "    # temp í´ë”ì˜ ëª¨ë“  JSON íŒŒì¼ ìˆ˜ì§‘\n",
    "    json_files = glob(os.path.join(temp_dir, \"patch_*.json\"))\n",
    "    all_cells = []\n",
    "    \n",
    "    print(f\"ğŸ“„ {len(json_files)}ê°œì˜ íŒ¨ì¹˜ JSON íŒŒì¼ ë³‘í•© ì¤‘...\")\n",
    "    \n",
    "    # ëª¨ë“  JSON íŒŒì¼ì—ì„œ ì„¸í¬ ë°ì´í„° ìˆ˜ì§‘\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, 'r') as f:\n",
    "            patch_cells = json.load(f)\n",
    "            all_cells.extend(patch_cells)\n",
    "    \n",
    "    # HnE ì„¸í¬ ë¶„ë¥˜ë¥¼ ìœ„í•œ í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ë§¤í•‘\n",
    "    class_colors = {\n",
    "        0: \"#FFA500\",  # Neutrophil - ì£¼í™©ìƒ‰\n",
    "        1: \"#008000\",  # Epithelial - ë…¹ìƒ‰\n",
    "        2: \"#FF0000\",  # Lymphocyte - ë¹¨ê°„ìƒ‰\n",
    "        3: \"#87CEEB\",  # Plasma - í•˜ëŠ˜ìƒ‰\n",
    "        4: \"#0000FF\",  # Eosinophil - íŒŒë€ìƒ‰sssssdasdasdasdasdasdasdasdasdasdã…ã„´ã…‡sds\n",
    "        5: \"#FFFF00\"   # Connective tissue - ë…¸ë€ìƒ‰\n",
    "    }\n",
    "    \n",
    "    class_names = {\n",
    "        0: \"Neutrophil\",\n",
    "        1: \"Epithelial\", \n",
    "        2: \"Lymphocyte\",\n",
    "        3: \"Plasma\",\n",
    "        4: \"Eosinophil\",\n",
    "        5: \"Connective tissue\"\n",
    "    }\n",
    "    \n",
    "    # ë£¨íŠ¸ ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±\n",
    "    root = ET.Element(\"ASAP_Annotations\")\n",
    "    \n",
    "    # Annotations ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±\n",
    "    annotations = ET.SubElement(root, \"Annotations\")\n",
    "    \n",
    "    # í•œ ë²ˆì— ëª¨ë“  ì„¸í¬ ì¶”ê°€\n",
    "    annotation_id = 0\n",
    "    for cell in all_cells:\n",
    "        cls_id = cell.get('cls_id', 0)\n",
    "        \n",
    "        annotation = ET.SubElement(annotations, \"Annotation\")\n",
    "        annotation.set(\"Name\", f\"Annotation {annotation_id}\")\n",
    "        annotation.set(\"Type\", \"Dot\")\n",
    "        annotation.set(\"PartOfGroup\", class_names.get(cls_id, f\"Class_{cls_id}\"))\n",
    "        annotation.set(\"Color\", class_colors.get(cls_id, \"#FFFFFF\"))\n",
    "        \n",
    "        coordinates = ET.SubElement(annotation, \"Coordinates\")\n",
    "        coordinate = ET.SubElement(coordinates, \"Coordinate\")\n",
    "        coordinate.set(\"Order\", \"0\")\n",
    "        coordinate.set(\"X\", str(float(cell['x'])))\n",
    "        coordinate.set(\"Y\", str(float(cell['y'])))\n",
    "        \n",
    "        annotation_id += 1\n",
    "    \n",
    "    # AnnotationGroups ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±\n",
    "    annotation_groups = ET.SubElement(root, \"AnnotationGroups\")\n",
    "    \n",
    "    # ê° í´ë˜ìŠ¤ë³„ ê·¸ë£¹ ìƒì„±\n",
    "    for cls_id, class_name in class_names.items():\n",
    "        group = ET.SubElement(annotation_groups, \"Group\")\n",
    "        group.set(\"Name\", class_name)\n",
    "        group.set(\"PartOfGroup\", \"None\")\n",
    "        group.set(\"Color\", class_colors.get(cls_id, \"#FFFFFF\"))\n",
    "        attributes = ET.SubElement(group, \"Attributes\")\n",
    "    \n",
    "    # XML ì €ì¥\n",
    "    rough_string = ET.tostring(root, 'unicode')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    pretty_xml = reparsed.toprettyxml(indent=\"\t\")\n",
    "    \n",
    "    # <?xml version... ë¼ì¸ì„ ì›í•˜ëŠ” í˜•íƒœë¡œ ìˆ˜ì •\n",
    "    lines = pretty_xml.split('\\n')\n",
    "    lines[0] = '<?xml version=\"1.0\"?>'\n",
    "    pretty_xml = '\\n'.join(lines[1:])  # ë¹ˆ ë¼ì¸ ì œê±°\n",
    "    \n",
    "    with open(xml_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(pretty_xml)\n",
    "    \n",
    "    print(f\"âœ… XML ë³€í™˜ ì™„ë£Œ: {len(all_cells)}ê°œ ì„¸í¬\")\n",
    "    return len(all_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2021d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvips\n",
    "import shutil\n",
    "\n",
    "slide_path=glob('../../data/*_HnE/*.ndpi')\n",
    "image_size=1024 # ëª¨ë¸ ì…ë ¥ í¬ê¸°\n",
    "origin_mpp=0.25\n",
    "output_mpp=0.5\n",
    "original_size=int(image_size*output_mpp/origin_mpp) #1122\n",
    "magnification=original_size/image_size\n",
    "count=0\n",
    "\n",
    "for i in range(len(slide_path)):\n",
    "    file_name=os.path.basename(slide_path[i]).split('.')[0]\n",
    "    slide=openslide.OpenSlide(slide_path[i])\n",
    "    thumbnail=slide.get_thumbnail((slide.dimensions[0]//64, slide.dimensions[1]//64))\n",
    "    slide = pyvips.Image.new_from_file(slide_path[i])\n",
    "\n",
    "    thumb_mask=cv2.threshold(255-np.array(thumbnail.convert('L')),30,255,cv2.THRESH_BINARY)[1]\n",
    "    thumb_mask=cv2.morphologyEx(thumb_mask,cv2.MORPH_CLOSE,np.ones((15,15),np.uint8))\n",
    "    thumb_mask=cv2.morphologyEx(thumb_mask,cv2.MORPH_OPEN,np.ones((5,5),np.uint8))\n",
    "    \n",
    "    # íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "    output_xml_path = f\"../../results/BR_HnE/cell_detection/{file_name}.xml\"\n",
    "    temp_dir = f\"../../results/BR_HnE/cell_detection/{file_name}_temp\"\n",
    "    os.makedirs(\"../../results/BR_HnE/cell_detection\", exist_ok=True)\n",
    "    \n",
    "    # temp í´ë” ì´ˆê¸°í™” (ê¸°ì¡´ í´ë” ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±)\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "    os.makedirs(temp_dir)\n",
    "    \n",
    "    total_cells_detected = 0\n",
    "    patch_counter = 0  # íŒ¨ì¹˜ ID ì¹´ìš´í„°\n",
    "    row_pbar = tqdm(range(slide.width//image_size-1), total=slide.width//image_size-1)\n",
    "    \n",
    "    for patch_row in row_pbar:\n",
    "        for patch_col in range(slide.height//image_size-1):\n",
    "            if np.sum(thumb_mask[(patch_col*image_size)//64:((patch_col+1)*image_size)//64,(patch_row*image_size)//64:((patch_row+1)*image_size)//64])>0:\n",
    "                count+=1\n",
    "                patch=slide.crop(patch_row*image_size, patch_col*image_size, image_size, image_size)\n",
    "                patch=np.ndarray(buffer=patch.write_to_memory(),\n",
    "                            dtype=np.uint8,\n",
    "                            shape=[patch.height, patch.width, patch.bands])\n",
    "                patch = cv2.resize(np.array(patch)[:,:,:3], (512, 512))\n",
    "                torch_patch=torch.from_numpy(patch).permute(2,0,1).unsqueeze(0).float()/255.\n",
    "                torch_patch=torch_patch.to(device)\n",
    "                cell_list = pred_patch(torch_patch, model, patch_row*image_size, patch_col*image_size, 2)\n",
    "                \n",
    "                # ğŸš€ ê°œë³„ JSON íŒŒì¼ë¡œ ì €ì¥ (íŒŒì¼ íŒŒì‹± ì „í˜€ ì—†ìŒ!)\n",
    "                if len(cell_list) > 0:\n",
    "                    save_patch_cells_to_json(cell_list, temp_dir, patch_counter)\n",
    "                    total_cells_detected += len(cell_list)\n",
    "                \n",
    "                patch_counter += 1  # íŒ¨ì¹˜ ID ì¦ê°€\n",
    "                s = f\"ì²˜ë¦¬ëœ íŒ¨ì¹˜: {count}, ì´ ê²€ì¶œëœ ì„¸í¬: {total_cells_detected}\"\n",
    "                row_pbar.set_description(f'{s}')\n",
    "\n",
    "    # ğŸ¯ ì²˜ë¦¬ ì™„ë£Œ í›„ ëª¨ë“  ê°œë³„ JSON â†’ XML ì¼ê´„ ë³€í™˜\n",
    "    print(f\"\\nğŸ“„ ê°œë³„ JSON íŒŒì¼ë“¤ ë³‘í•©í•˜ì—¬ XML ë³€í™˜ ì¤‘...\")\n",
    "    final_cell_count = merge_patch_jsons_to_xml(temp_dir, output_xml_path)\n",
    "    \n",
    "    # temp í´ë” ì „ì²´ ì‚­ì œ\n",
    "    shutil.rmtree(temp_dir)\n",
    "    \n",
    "    print(f\"ğŸ¯ WSI ì²˜ë¦¬ ì™„ë£Œ! ì´ {final_cell_count}ê°œ ì„¸í¬ ê²€ì¶œë¨\")\n",
    "    print(f\"ğŸ“„ XML íŒŒì¼ ì €ì¥ ìœ„ì¹˜: {output_xml_path}\")\n",
    "    print(f\"ğŸ—‘ï¸  ì„ì‹œ í´ë” ì •ë¦¬ ì™„ë£Œ\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
